## Methods {#sec:methods}

PhenoPLIER is a comprehensive framework designed to integrate gene-trait associations with drug-induced transcriptional responses by utilizing groups of functionally-related genes, known as gene modules or latent variables (LVs).
The computation of gene-trait associations is performed using the PrediXcan family of methods, while the inference of latent variables is carried out through the MultiPLIER models, which are applied to extensive gene expression datasets.

The functionalities of PhenoPLIER include:
1) A regression model that calculates the association between an LV and a trait;
2) A consensus clustering method used in the latent space to identify both shared and unique transcriptomic features across traits;
3) A clear, LV-centered framework for drug repurposing.

Detailed descriptions of these methodologies are provided below.


### The PrediXcan family of methods for gene-based associations {#sec:methods:predixcan}

We utilized two gene-based statistical methods, Summary-PrediXcan (S-PrediXcan) [@doi:10.1038/s41467-018-03621-1] and Summary-MultiXcan (S-MultiXcan) [@doi:10.1371/journal.pgen.1007889], both of which are part of the PrediXcan family [@doi:10.1038/ng.3367].
These methods are collectively referred to as transcription-wide association studies (TWAS).
S-PrediXcan analyzes the univariate association between a trait and the predicted expression of a gene in a single tissue.
On the other hand, S-MultiXcan assesses the joint association of a gene's predicted expression across multiple tissues with a trait.
Both S-PrediXcan and S-MultiXcan utilize GWAS summary statistics, eliminating the need for individual-level genotype and phenotype data.

Here, we provide essential details on the Transcriptome-Wide Association Study (TWAS) methods relevant to our later discussion of the regression framework (for more comprehensive information, refer to the cited articles).
In our analysis, we denote $\mathbf{y}$ as the vector representing traits of $n$ individuals, which we have centered to eliminate the need for an intercept.
The predicted gene expression across individuals in tissue type $l$ is represented by $\tilde{\mathbf{t}}_l = \sum_{a \in \mathrm{model}_l} w_{a}^{l} X_{a}$, where $X_a$ is the genotype of single nucleotide polymorphism (SNP) $a$, and $w_{a}^{l}$ is its corresponding weight in the tissue-specific prediction model $l$.
The standardized form of $\tilde{\mathbf{t}}_l$, denoted as $\mathbf{t}_l$, has a mean of zero and a standard deviation of one.

S-PrediXcan [@doi:10.1038/s41467-018-03621-1] is a streamlined version of PrediXcan [@doi:10.1038/ng.3367], which models a trait as a linear function of gene expression in a single tissue using a univariate model:

$$
\mathbf{y} = \mathbf{t}_l \gamma_l + \bm{\epsilon}_l,
$$ {#eq:predixcan}

In this equation, $\hat{\gamma}_l$ represents the estimated effect size or regression coefficient, and $\bm{\epsilon}_l$ denotes the error terms with a variance of $\sigma_{\epsilon}^{2}$.
The significance of the gene-tissue association is quantified using the $z$-score, calculated as $\hat{z}_{l}=\hat{\gamma}_l / \mathrm{se}(\hat{\gamma}_l)$ for a specific gene's tissue model $l$.
Unlike PrediXcan, which requires individual-level data, S-PrediXcan estimates the PrediXcan $z$-scores using only GWAS summary statistics, as shown below:

$$
\hat{z}_{l} \approx \sum_{a \in model_{l}} w_a^l \frac{\hat{\sigma}_a}{\hat{\sigma}_l} \frac{\hat{\beta}_a}{\mathrm{se}(\hat{\beta}_a)},
$$ {#eq:spredixcan}

Here, $\hat{\sigma}_a$ and $\hat{\sigma}_l$ are the variances of SNP $a$ and the predicted gene expression in tissue $l$, respectively, and $\hat{\beta}_a$ is the estimated effect size of SNP $a$ from the GWAS.
These Transcriptome-Wide Association Study (TWAS) methods consistently use the Genotype-Tissue Expression project (GTEx v8) [@doi:10.1126/science.aaz1776] as the reference panel for estimating genotype variances and covariances.
S-PrediXcan provides insights into the tissue-specific direction of effects, such as whether a higher or lower predicted expression of a gene increases or decreases disease risk.
This information was instrumental in our drug repurposing strategy, detailed later in the manuscript.

S-MultiXcan [@doi:10.1371/journal.pgen.1007889] serves as the summary version of MultiXcan, which itself is noted for being more effective than PrediXcan in identifying gene-trait associations.
However, MultiXcan does not indicate the direction of these effects.
The primary output from MultiXcan is the $p$-value, calculated using an F-test, for a model involving multiple tissues:

$$
\begin{split}
\mathbf{y} & = \sum_{l=1}^{p} \mathbf{t}_l g_l + \mathbf{e} \\
& = \mathbf{T} \mathbf{g} + \mathbf{e},
\end{split}
$$ {#eq:multixcan}

In this model, $\mathbf{T}$ represents a matrix consisting of $p$ columns $\mathbf{t}_l$, $\hat{g}_l$ denotes the estimated effect size for the predicted gene expression in tissue $l$ (thus $\hat{\mathbf{g}}$ is a vector of these $p$ estimated effect sizes $\hat{g}_l$), and $\mathbf{e}$ are the error terms with variance $\sigma_{e}^{2}$.
Due to the high correlation among predicted expression values for a gene across different tissues, MultiXcan employs the principal components (PCs) of $\mathbf{T}$ to mitigate collinearity issues.
S-MultiXcan calculates the joint regression estimates (effect sizes and their variances) in Equation (@eq:multixcan) by utilizing the marginal estimates from S-PrediXcan in Equation (@eq:spredixcan).
Under the null hypothesis of no association, the test statistic $\hat{\mathbf{g}}^{\top} \frac{\mathbf{T}^{\top}\mathbf{T}}{\sigma_{e}^{2}} \hat{\mathbf{g}}$ follows a chi-squared distribution with $p$ degrees of freedom.
The significance of the association in S-MultiXcan is estimated with:

$$
\begin{split}
\frac{\hat{\mathbf{g}}^{\top} (\mathbf{T}^{\top}\mathbf{T}) \hat{\mathbf{g}}}{\sigma_{e}^{2}} & \approx \bm{\hat{\gamma}}^{\top} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \left(\frac{\mathbf{T}^{\top} \mathbf{T}}{n-1}\right)^{-1} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \bm{\hat{\gamma}} \\
& = \hat{\mathbf{z}}^{\top} Cor(\mathbf{T})^{-1} \hat{\mathbf{z}},
\end{split}
$$ {#eq:smultixcan}

Here, $\hat{\mathbf{z}}$ is a vector containing $p$ $z$-scores (Equation (@eq:spredixcan)) for each available tissue for the gene, and $Cor(\mathbf{T})$ is the autocorrelation matrix of $\mathbf{T}$.
Given that $\mathbf{T}^{\top}\mathbf{T}$ is often singular for many genes, S-MultiXcan computes the pseudo-inverse $Cor(\mathbf{T})^{+}$ using the top $k$ PCs.
As a result, $\hat{\mathbf{z}}^{\top} Cor(\mathbf{T})^{+} \hat{\mathbf{z}}$ follows a $\chi_k^2$ distribution.
To derive this expression, S-MultiXcan assumes that $\sigma_{e}^{2} \approx \sigma_{\epsilon}^{2}$, implying that the variance of the error terms in the joint regression is approximately equal to the residual variance of the marginal regressions.
It is important to note that while $Cor(\mathbf{T})$ is estimated using a global genotype covariance matrix, the marginal $\hat{z}_l$ in Equation (@eq:spredixcan) are approximated using tissue-specific genotype covariances.
Although S-MultiXcan generally provides estimates highly concordant with those of MultiXcan, the results are not perfectly correlated across genes [@doi:10.1371/journal.pgen.1007889].
These nuances are crucial for our LV-based regression model when calculating the gene-gene correlation matrix.
We incorporated S-MultiXcan results into our LV-based regression model and our trait cluster analyses.


### TWAS resources {#sec:methods:twas}

We used two large TWAS resources from different cohorts for discovery and replication, all obtained from European ancestries.
PhenomeXcan [@doi:10.1126/sciadv.aba2083], our discovery cohort, provides results on 4,091 traits across different categories.
Supplementary Data 1 has all the details about the included GWAS, sample size and disease/trait categories.
In PhenomeXcan, these publicly available GWAS summary statistics were used to compute
1) gene-based associations with the PrediXcan family of methods (described before), and
2) a posterior probability of colocalization between GWAS loci and *cis*-eQTL with fastENLOC [@doi:10.1126/sciadv.aba2083; @doi:10.1016/j.ajhg.2020.11.012].
We refer to the matrix of $z$-scores from S-PrediXcan (Equation (@eq:spredixcan)) across $q$ traits and $m$ genes in tissue $t$ as $\mathbf{M}^{t} \in \mathbb{R}^{q \times m}$.
As explained later, matrices $\mathbf{M}^{t}$ were used in our LV-based drug repurposing framework since they provide direction of effects.
The S-MultiXcan results (22,515 gene associations across 4,091 traits) were used in our LV-based regression framework and our cluster analyses of traits.
For the cluster analyses, we used the $p$-values converted to $z$-scores: $\mathbf{M}=\Phi^{-1}(1 - p/2)$, where $\Phi^{-1}$ is the probit function.
Higher $z$-scores correspond to stronger associations.

Our discovery cohort was eMERGE [@doi:10.1038/gim.2013.72], where the same TWAS methods were run on 309 phecodes [@doi:10.1101/2021.10.21.21265225] across different categories (more information about traits are available in [@doi:10.1101/2021.10.21.21265225]).
We used these results to replicate the associations found with our LV-based regression framework in PhenomeXcan.


### MultiPLIER and Pathway-level information extractor (PLIER) {#sec:methods:multiplier}

The MultiPLIER method [@doi:10.1016/j.cels.2019.04.003] identifies patterns of co-expressed genes using the recount2 dataset [@doi:10.1038/nbt.3838], specifically excluding GTEx samples.
This dataset encompasses a vast array of gene expression profiles.
MultiPLIER employs the PLIER algorithm [@doi:10.1038/s41592-019-0456-1], which is an unsupervised learning technique that integrates known canonical pathways to minimize technical variability in the data.
This method utilizes a matrix factorization technique to decompose gene expression data into a series of latent variables (LVs), with each LV corresponding to a distinct gene module.
In the application to recount2, MultiPLIER effectively reduced the dataset's dimensionality to 987 LVs.

The manuscript presents a method for analyzing a gene expression dataset $\mathbf{Y}^{m \times c}$, which consists of $m$ genes under $c$ experimental conditions.
Additionally, a prior knowledge matrix $\mathbf{C} \in \{0,1\}^{m \times p}$ is utilized, representing $p$ pathways from the MSigDB database [@doi:10.1016/j.cels.2015.12.004].
Here, $\mathbf{C}_{ij} = 1$ indicates that gene $i$ is part of pathway $j$.
The method, known as PLIER, computes matrices $\mathbf{U}$, $\mathbf{Z}$, and $\mathbf{B}$ by minimizing the following objective function:

$$
||\mathbf{Y} - \mathbf{Z}\mathbf{B}||^{2}_{F} + \lambda_1 ||\mathbf{Z} - \mathbf{C}\mathbf{U}||^{2}_{F} + \lambda_2 ||\mathbf{B}||^{2}_{F} + \lambda_3 ||\mathbf{U}||_{L^1}
$$ {#eq:met:plier_func}

The constraints for this optimization are $\mathbf{U}>0$ and $\mathbf{Z}>0$.
The matrix $\mathbf{Z}^{m \times l}$ represents the gene loadings across $l$ latent variables, $\mathbf{B}^{l \times c}$ encapsulates the latent space for the $c$ conditions, and $\mathbf{U}^{p \times l}$ determines the representation of each of the $p$ pathways in $\mathbf{C}$ for every latent variable.
The regularization parameters $\lambda_i$ are employed to control the complexity of the model during training.

$\mathbf{Z}$ provides a reduced-dimensional representation of the gene space, aiming to align closely with the prior knowledge embedded in $\mathbf{C}$.
This alignment may reveal either known or novel gene modules, which are significant biological patterns, or it may simply represent noise in the data.

For our analyses on drug repurposing and clustering, we utilized a model to map associations from gene traits (from TWAS) and gene-drug interactions (from LINCS L1000) into a reduced-dimensional space defined by gene modules.
Specifically, we projected the TWAS associations $\mathbf{M}$ (obtained either through S-PrediXcan or S-MultiXcan) using the following equation:

$$
\hat{\mathbf{M}} = (\mathbf{Z}^{\top} \mathbf{Z} + \lambda_{2} \mathbf{I})^{-1} \mathbf{Z}^{\top} \mathbf{M},
$$ {#eq:proj}

In this equation, $\hat{\mathbf{M}}^{l \times q}$ represents a matrix where traits are linked to gene modules rather than individual genes.
We applied a similar methodology to project drug-induced transcriptional profiles from LINCS L1000, which allowed us to represent drugs in terms of gene modules.
This approach is elaborated upon in subsequent sections.


### Regression model for LV-trait associations {#sec:methods:reg}

We adapted the gene-set analysis framework from MAGMA [@doi:10.1371/journal.pcbi.1004219] to TWAS.
We used a competitive test to predict gene-trait associations from TWAS using gene weights from an LV, testing whether top-weighted genes for an LV are more strongly associated with the phenotype than other genes with relatively small or zero weights.
Thus, we fit the model

$$
\mathbf{m}=\beta_{0} + \mathbf{s} \beta_{s} + \sum_{i} \mathbf{x}_{i} \beta_{i} + \bm{\epsilon},
$$ {#eq:reg:model}

In this section of the Methods, we describe the statistical model used to analyze gene $p$-values in relation to latent variables and gene properties.
Specifically, $\mathbf{m}$ represents a vector of the S-MultiXcan gene $p$-values for a specific trait, transformed using $-log_{10}$.
The vector $\mathbf{s}$ serves as a binary indicator; it contains a value of 1 for genes ranked in the top 1% based on their loadings from latent variable (LV) $\ell$ in $\mathbf{Z}_{\ell}$, and 0 for all other genes.

The variable $\mathbf{x}_{i}$ denotes a gene property that is utilized as a covariate in the model.
The coefficients $\beta$, including $\beta_{0}$ which acts as the intercept, represent the effect sizes.
The error terms are captured by $\bm{\epsilon}$, which follows a multivariate normal distribution (MVN), expressed as $\mathrm{MVN}(0, \sigma^{2} \mathbf{R})$.
Here, $\sigma^{2}$ scales the covariance matrix $\mathbf{R}$, which itself represents the correlations between genes.

The model evaluates whether there is a significant difference in trait associations by testing the null hypothesis $\beta_{s} = 0$ against the alternative hypothesis $\beta_{s} > 0$.
Here, $\beta_{s}$ quantifies the difference in trait associations between genes within latent variable (LV) $\ell$ and those not included in it.
In line with the MAGMA analytical framework, we incorporated two gene characteristics as covariates in our analysis: 1) *gene size*, which is determined by the count of principal components (PCs) retained in S-MultiXcan, and 2) *gene density*, calculated as the ratio of the number of PCs to the available number of tissues.

Since the error terms $\bm{\epsilon}$ could be correlated, it is inappropriate to assume that they have independent normal distributions, as typically assumed in a standard linear regression model.
In the PrediXcan family of methods, the predicted expression of a pair of genes could be correlated if they share expression quantitative trait loci (eQTLs) or if these eQTLs are in linkage disequilibrium (LD) [@doi:10.1038/s41588-019-0385-z].
To address these correlations, we employed a generalized least squares approach.
We approximated the gene-gene correlation matrix $\mathbf{R}$ by calculating the correlations between the model sum of squares (SSM) for each gene pair under the null hypothesis of no association.
These correlations are derived from the individual-level MultiXcan model (Equation (@eq:multixcan)), where the predicted expression matrix $\mathbf{T}_{i} \in \mathbb{R}^{n \times p_i}$ of a gene $i$ across $p_i$ tissues is projected onto its top $k_i$ principal components (PCs), resulting in matrix $\mathbf{P}_{i} \in \mathbb{R}^{n \times k_i}$.
According to the MAGMA framework, the SSM for each gene is proportional to $\mathbf{y}^{\top} \mathbf{P}_{i} \mathbf{P}_{i}^{\top} \mathbf{y}$.
Under the null hypothesis of no association, the covariances between the SSM of genes $i$ and $j$ are therefore given by $2 \times \mathrm{Trace}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})$.
The standard deviations of each SSM are calculated as $\sqrt{2 \times k_{i}} \times (n - 1)$.
Consequently, the correlation between the SSMs for genes $i$ and $j$ can be expressed as:

$$
\begin{split}
\mathbf{R}_{ij} & = \frac{2 \times \mathrm{Tr}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}} \times (n - 1)^2} \\
& = \frac{2 \times \mathrm{Tr}(Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \times Cor(\mathbf{P}_{j}, \mathbf{P}_{i}))}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}}},
\end{split}
$$ {#eq:reg:r}

where $\mathbf{P}$ columns are standardized, $\mathrm{Tr}$ denotes the trace of a matrix, and the cross-correlation matrix between PCs, $Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \in \mathbb{R}^{k_i \times k_j}$, is defined by

$$
\begin{split}
Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) & = Cor(\mathbf{T}_{i} \mathbf{V}_{i}^{\top} \mathrm{diag}(\lambda_i)^{-1/2}, \mathbf{T}_{j} \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2}) \\
& = \mathrm{diag}(\lambda_i)^{-1/2} \mathbf{V}_{i} \left(\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1}\right) \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2},
\end{split}
$$ {#eq:reg:cor_pp}

where $\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1} \in \mathbb{R}^{p_i \times p_j}$ represents the cross-correlation matrix between the predicted expression levels of genes $i$ and $j$.
The columns of $\mathbf{V}_{i}$ and the scalars $\lambda_i$ are the eigenvectors and eigenvalues of $\mathbf{T}_{i}$, respectively.
To estimate the correlation of predicted expression levels for genes $i$ in tissue $k$ and gene $j$ in tissue $l$, $(\mathbf{t}_k^i, \mathbf{t}_l^j)$ ($\mathbf{t}_k^i$ is the $k$th column of $\mathbf{T}_{i}$), we used [@doi:10.1371/journal.pgen.1007889]

$$
\begin{split}
\frac{(\mathbf{T}_{i}^{\top} \mathbf{T}_{j})_{kl}}{n-1} & = Cor(\mathbf{t}_k^i, \mathbf{t}_l^j) \\
& = \frac{ Cov(\mathbf{t}_k, \mathbf{t}_l) } { \sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
& = \frac{ Cov(\sum_{a \in \mathrm{model}_k} w_a^k X_a, \sum_{b \in \mathrm{model}_l} w_b^l X_b) }  {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
& = \frac{ \sum_{\substack{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l}} w_a^k w_b^l Cov(X_a, X_b)} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
& = \frac{ \sum_{\substack{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l}} w_a^k w_b^l \Gamma_{ab}} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} },
\end{split}
$$ {#eq:reg:corr_genes}

where $X_a$ is the genotype of SNP $a$, $w_a^k$ is the weight of SNP $a$ for gene expression prediction in the tissue model $k$, and $\Gamma = \widehat{\mathrm{var}}(\mathbf{X}) = (\mathbf{X} - \bar{\mathbf{X}})^{\top} (\mathbf{X} - \bar{\mathbf{X}}) / (n-1)$ is the genotype covariance matrix using GTEx v8 as the reference panel, which is the same used in all TWAS methods described here.
The variance of the predicted expression values of gene $i$ in tissue $k$ is estimated as [@doi:10.1038/s41467-018-03621-1]:

$$
\begin{split}
\widehat{\mathrm{var}}(\mathbf{t}_k^i) & = (\mathbf{W}^k)^\top \Gamma^k \mathbf{W}^k \\
& = \sum_{\substack{a \in \mathrm{model}_k \\ b \in \mathrm{model}_k}} w_a^k w_b^k \Gamma_{ab}^k.
\end{split}
$$ {#eq:reg:var_gene}

Revised paragraph:

In our study, we employed the MultiXcan regression model, as detailed in Equation (@eq:multixcan).
It is important to note that $\mathbf{R}$, within this context, serves as an approximation of gene correlations specifically for the S-MultiXcan model.
S-MultiXcan, as previously described, utilizes the marginal regression estimates from S-PrediXcan (see Equation (@eq:spredixcan)) and integrates these with a set of simplifying assumptions and distinct genotype covariance matrices.
This integration complicates the process of deriving a solution tailored to S-MultiXcan for computing $\mathbf{R}$.

To manage this complexity, we opted to use a submatrix, $\mathbf{R}_{\ell}$, which includes only the genes within the top 1% of a latent variable (LV) $\ell$, rather than using the full matrix $\mathbf{R}$.
This approach is considered conservative, focusing on correlations among the most significant genes.
Our simulation results, discussed in [Supplementary Note 1](#sm:reg:null_sim), indicate that the model is generally well-calibrated, effectively adjusting for LVs that include adjacent and highly correlated top genes (refer to Figure @fig:reg:nulls:qqplot:lv234).
However, the simulation also revealed that the model was not well-calibrated for 127 LVs (see Figure @fig:reg:nulls:qqplot:lv914).
This issue likely stems from challenges in accurately computing the gene correlation matrix, leading us to exclude these LVs from our primary analysis.

In Equation (1), we focused on tissue models available in the S-PrediXcan results and considered only those SNPs that were also present in the GWAS datasets used for the transcriptome-wide association studies (TWAS).
This approach is critical for deriving more precise correlation estimates [@doi:10.1371/journal.pgen.1007889].
Consequently, we generated distinct correlation matrices for the PhenomeXcan and eMERGE analyses.
For PhenomeXcan, the majority of the GWAS data (4,049 studies) were sourced from the UK Biobank, utilizing a consistent pipeline and SNP set, allowing us to use a single correlation matrix for these studies.
For other traits, a unique correlation matrix was applied to each set of traits that shared the same or a majority of SNPs.

We ran our regression model for all 987 LVs across the 4,091 traits in PhenomeXcan.
For replication, we ran the model in the 309 phecodes in eMERGE.
We adjusted the $p$-values using the Benjamini-Hochberg procedure.


### LV-based drug repurposing approach {#sec:methods:drug}

For the drug-disease prediction, we implemented an LV-based method adapted from a drug repositioning framework previously utilized for psychiatry traits [@doi:10.1038/nn.4618].
This framework identifies genes associated with a trait whose expression is inversely related to the expression profiles of drugs.
We then compared our LV-based approach to this earlier single-gene method.
In the single-gene approach, we calculated a drug-disease score by multiplying the matrix of signed $z$-scores for each tissue $t$, denoted as $\mathbf{M}^t$, with another matrix of signed $z$-scores derived from transcriptional responses in the LINCS L1000 dataset [@doi:10.1016/j.cell.2017.10.049], represented as $\mathbf{L}^{c \times m}$ (for $c$ compounds).
The matrix $\mathbf{M}^t$ indicates whether a higher or lower predicted expression of a gene is linked to disease risk, while $\mathbf{L}$ shows whether a drug increases or decreases gene expression.
Multiplying these two matrices yields a score for each drug-disease pair, computed as $\mathbf{D}^{t,k}=-1 \cdot \mathbf{M}^{t,k} \mathbf{L}^\top$, where $k$ represents the number of most significant gene associations in $\mathbf{M}^t$ for each trait.
Following the suggestions in [@doi:10.1038/nn.4618], $k$ could include all genes or the top 50, 100, 250, and 500 genes; we then averaged the score ranks across all $k$ to obtain $\mathbf{D}^t$.
Finally, for each drug-disease pair, we selected the highest prediction score across all tissues, defined as $\mathbf{D}_{ij} = \max \{ \mathbf{D}_{ij}^t \mid \forall t \}$.


We applied the same methodology to the LV-based approach, where the matrices $\mathbf{M}^{t}$ and $\mathbf{L}$ were projected into the gene module latent space as per Equation (@eq:proj).
This projection resulted in $\hat{\mathbf{M}}^t$ and $\hat{\mathbf{L}}^{l \times c}$.
Subsequently, we computed $\mathbf{D}^{t,k}$ as $\mathbf{D}^{t,k} = -1 \cdot \hat{\mathbf{L}}^{\top} \hat{\mathbf{M}}^{t,k}$.
Here, $k$ represents either all latent variables (LVs) or a subset of the top 5, 10, 25, or 50 LVs, acknowledging that the number of LVs is an order of magnitude smaller than the number of genes.


Since the gold standard of drug-disease medical indications is described with Disease Ontology IDs (DOID) [@doi:10.1093/nar/gky1032], we mapped PhenomeXcan traits to the Experimental Factor Ontology [@doi:10.1093/bioinformatics/btq099] using [@url:https://github.com/EBISPOT/EFO-UKB-mappings], and then to DOID.


### Consensus clustering of traits {#sec:methods:clustering}

We conducted two preprocessing steps on the S-MultiXcan results prior to performing cluster analysis.
Initially, we aggregated the results in matrix $\mathbf{M}$, where $p$-values were converted to $z$-scores as previously described, for traits associated with the same Experimental Factor Ontology (EFO) term [@doi:10.1093/bioinformatics/btq099].
This aggregation was conducted using Stouffer's method, expressed mathematically as $\sum w_i M_{ij} / \sqrt{\sum w_i^2}$, where $w_i$ represents the weight derived from the GWAS sample size for trait $i$, and $M_{ij}$ denotes the $z$-score for gene $j$.
Subsequently, to minimize the influence of traits with extensive polygenic effects, we normalized the $z$-scores for each trait $i$ by their cumulative sum: $M_{ij} / \sum M_{ij}$.
Following these preprocessing steps, we applied Equation (@eq:proj) to project this data matrix, resulting in $\hat{\mathbf{M}}$ which included data for 3,752 traits and 987 latent variables (LVs).
This projected matrix served as the input for our clustering analysis.


In the process of clustering $\hat{\mathbf{M}}$, which involves $n$ traits, we categorize them into $k$ clusters, denoted by a label vector $\pi \in \mathbb{N}^n$.
The methodology for consensus clustering is divided into two primary steps: 1) creating an ensemble $\Pi$ consisting of $r$ partitions of the dataset, represented as $\Pi=\{\pi_1, \pi_2, \ldots, \pi_r\}$, and 2) merging these partitions into a unified solution defined by the following equation:

$$
\pi^* = \mathrm{arg}\,\underset{\hat{\pi}}{\max} Q(\{ \lvert \mathcal{L}^i \lvert \phi(\hat{\pi}_{\mathcal{L}^i}, \pi_{i \mathcal{L}^i}) \mid i \in \{1,\ldots,r\} \}),
$$ {#eq:consensus:obj_func}

Here, $\mathcal{L}^i$ represents a set of data indices with predetermined cluster labels for the $i$-th partition.
The function $\phi\colon \mathbb{N}^n \times \mathbb{N}^n \to \mathbb{R}$ quantifies the similarity between two partitions.
The function $Q$ is a measure of central tendency, such as the mean or median.
In our analysis, we employed the adjusted Rand index (ARI) [@doi:10.1007/BF01908075] as the similarity measure $\phi$ and chose the median as the measure $Q$. 

To determine $\pi^*$, a consensus function $\Gamma\colon \mathbb{N}^{n \times r} \to \mathbb{N}^n$ is defined, taking $\Pi$ as input.
Our consensus functions are based on the evidence accumulation clustering (EAC) approach [@doi:10.1109/TPAMI.2005.113].
In this approach, $\Pi$ is first converted into a distance matrix $\mathbf{D}_{ij} = d_{ij} / r$, where $d_{ij}$ counts how often traits $i$ and $j$ were placed in different clusters across all $r$ partitions.
Finally, $\Gamma$ employs a similarity-based clustering algorithm applied to $\mathbf{D}$ to obtain the final partition $\pi^*$.


For the ensemble generation step, we employed various algorithms to create a diverse set of partitions, as depicted in Figure @fig:clustering:design.
The importance of diversity in ensembles is well-documented [@doi:10.1016/j.ins.2016.04.027; @doi:10.1109/TPAMI.2011.84; @doi:10.1016/j.patcog.2014.04.005].
We utilized three different data representations: the original dataset, its transformation into the top 50 principal components, and the embedding produced by UMAP [@arxiv:1802.03426] using 50 components.
For each data representation, we applied five distinct clustering algorithms, each based on different assumptions about the data structure: $k$-means [@Arthur2007], spectral clustering [@Ng2001], Gaussian mixture models (GMM), hierarchical clustering, and DBSCAN [@Ester1996].
For $k$-means, spectral clustering, and GMM, we set the number of clusters, $k$, to range from 2 to $\sqrt{n} \approx 60$.
We generated five partitions for each value of $k$ using random seeds.
In hierarchical clustering, we produced four partitions for each $k$, employing common linkage criteria: ward, complete, average, and single.
For DBSCAN, we varied the parameters $\epsilon$ (the maximum distance between two points considered to be in the same neighborhood) and *minPts* (the minimal number of points in a neighborhood required for a point to be classified as a core point), as per the method described in [@doi:10.1088/1755-1315/31/1/012012].
We selected *minPts* values ranging from 2 to 125.
We determined a plausible range of $\epsilon$ values for each data representation (raw, PCA, and UMAP) by analyzing the distribution of the mean distances of the *minPts*-nearest neighbors across all data points.
To address potential issues where some combinations of *minPts* and $\epsilon$ might not yield meaningful partitions (e.g., when all points are considered noise or only one cluster is identified), we resampled partitions created by DBSCAN to ensure balanced representation of this algorithm in the ensemble.
This approach resulted in a final ensemble comprising 4,428 partitions of 3,752 traits.


To finalize our analysis, we applied spectral clustering to the matrix $\mathbf{D}$, converting it into a similarity matrix.
This transformation was achieved by employing an RBF kernel, specifically $\mathrm{exp}(-\gamma \mathbf{D}^2)$.
We tested four different values of $\gamma$, which were empirically chosen for optimal performance.
For each cluster number $k$ ranging from 2 to 60, we generated four potential consensus partitions.
From these, we selected the partition that maximized the objective function as specified in Equation (1).
Subsequently, we refined our results by retaining only those partitions that had an ensemble agreement exceeding the 75th percentile, as illustrated in Figure 2.
This process resulted in 15 final consensus partitions, which are displayed in Figure 3.

The data used in our clustering analysis undergoes a series of both linear and nonlinear transformations, which include Principal Component Analysis (PCA), Uniform Manifold Approximation and Projection (UMAP), and ensemble transformation utilizing the Evidence Accumulation Clustering (EAC) paradigm, where a distance matrix $\mathbf{D}$ is used.
While consensus clustering is beneficial for analyzing biological data [@pmid:27303057], these transformations can make it challenging to interpret the results.
To address this, we employed a supervised learning strategy to identify key gene modules or latent variables (LVs) that are significant for each cluster of traits, as shown in Figure {@fig:clustering:design}b.
It is important to note that this supervised model was not used for prediction purposes, but rather to identify which LVs were most discriminative for each cluster.

We selected the highest resolution partition ($k=29$, although other partitions could also be used) to train a decision tree model.
This model used the clusters as labels and the projected data $\hat{\mathbf{M}}$ as training samples.
For each $k$, we generated binary labels, designating the traits within the current cluster as the positive class and all other traits as the negative class.
We then determined the LV at the root node of the trained model, selecting it only if its threshold was positive and exceeded one standard deviation.
This LV was subsequently removed from $\hat{\mathbf{M}}$, whether previously selected or not, and the model was retrained.
This process was repeated 20 times to identify the top 20 LVs that most effectively distinguish traits within a cluster from those outside of it.

In [Supplementary Note 2](#sm:clustering:null_sim), we performed several analyses under a null hypothesis of no structure in the data to verify that the clustering results detected by this pipeline were real.


### CRISPR-Cas9 screening {#sec:methods:crispr}

**Cell Culture Methods**

HepG2 cells, sourced from ATCC (ATCC® HB-8065™), were cultured in Eagle's Minimum Essential Medium containing L-Glutamine (EMEM, Cat.
No.
112-018-101, Quality Biology).
The medium was enriched with 10% Fetal Bovine Serum (FBS, Gibco, Cat.
No.
16000-044) and 1% Penicillin/Streptomycin (Pen/Strep, Gibco, Cat.
No.
15140-122).
Culturing conditions included maintaining the cells at a temperature of 37°C in a humidity-controlled incubator supplemented with 5% CO2.
The cells were grown in Collagen-I coated flasks and were not allowed to exceed 80% confluency to ensure optimal growth and viability.

**Genome-wide Lentiviral Pooled CRISPR-Cas9 Library Application**

The third-generation lentiviral system, specifically the Broad GPP genome-wide Human Brunello CRISPR knockout pooled library, was sourced from David Root and John Doench via Addgene (Catalog No.
73179-LV).
This library was utilized for transducing HepG2 cells.
It comprises 76,441 single-guide RNAs (sgRNAs) that target 19,114 human genes, averaging four sgRNAs per gene.
Each sgRNA cassette, which is 20 nucleotides long, was integrated into the lentiCRISPRv2 vector.
This integration occurred between the U6 promoter and the gRNA scaffold. 

For the transduction process, lentiviral vectors carrying the Cas9 gene were employed to introduce the sgRNA-containing plasmids into the cells during their replication phase.
Cells that did not successfully undergo transduction were removed via puromycin selection.

**Lentiviral Titer Determination Methodology**

For the lentiviral titer determination, a no-spin transduction approach was employed.
Approximately 2.5 million cells were seeded in each well of a Collagen-I coated 6-well plate.
Each well received 8 µg/ml of polybrene (Millipore Sigma, Cat.
TR-1003 G) and varying volumes of virus (specifically 0, 50, 100, 200, 250, and 400 µl).
The total volume in each well was adjusted to 1.24 ml with the addition of EMEM complete media.

Approximately 16-18 hours after transduction, the media containing the virus and polybrene was removed.
The cells were then washed twice with 1x DPBS and supplied with fresh EMEM.
At 24 hours post-transduction, cells from each well were trypsinized, diluted (for instance, 1:10), and re-seeded into paired wells of a new 6-well plate.
At 60 hours post-transduction, the media in each well was replaced with fresh EMEM.
In one well of each pair, 2 µg/ml of puromycin (Gibco, Cat.
A1113803) was added.

After 2-5 days of puromycin selection, or when no surviving cells were observed in the control well (0 virus volume) treated with puromycin, cells from both wells (with and without puromycin) were collected and counted to assess viability.
The Percentage of Infection (PI%) was calculated by comparing the cell counts from wells with and without puromycin selection.

Using Poisson's distribution theory, an optimal transduction efficiency (PI%) of 30-50% corresponds to a Multiplicity of Infection (MOI) of approximately 0.35-0.70.
At an MOI of about 0.3, around 25% of cells are typically infected, predominantly with a single copy of the virus.
Based on these findings, a virus volume that achieves a transduction efficiency of 30-40% (120 µl) was selected for subsequent large-scale viral transduction experiments.

**Lentiviral Transduction in HepG2 Using Brunello CRISPR Knockout Pooled Library.** To achieve a target coverage of at least 500 cells per single-guide RNA (sgRNA), and to maintain a multiplicity of infection (MOI) between 0.3-0.4—thus ensuring that 95% of the infected cells receive only one viral particle—approximately 200 million cells were initially prepared for the screening process.
The transduction procedure was performed as previously described.
Briefly, 2.5 million cells were seeded into each well of fourteen 6-well plates, supplemented with 8 µg/ml of polybrene.
A volume of 120 µl of the viral solution was added to each experimental well.
Eighteen hours after transduction, the medium containing virus and polybrene (virus/PB mix) was removed, and the cells from each well were harvested, counted, and pooled into T175 flasks.
At 60 hours post-transduction, 2 µg/ml of puromycin was added to each flask.
The medium was refreshed every two days with fresh Eagle's Minimum Essential Medium (EMEM), containing 2 µg/ml puromycin.
Seven days following the commencement of puromycin selection, the cells were again collected, pooled, counted, and replated.

**Fluorescent Dye Staining Procedure**

Nine days post-puromycin selection, cells were divided into two groups.
The first group, labeled as the Unsorted Control, consisted of 20-30 million cells.
These cells were centrifuged at 500 x g for 5 minutes at 4°C.
The resulting cell pellet was then stored at -80°C for subsequent genomic DNA extraction.

The remaining cells, approximately 200 million, were placed in 100 mm dishes for fluorescent staining.
The fluorescent dye used was LipidSpot™ 488 (Biotium, Cat.
70065-T).
For the staining process, LipidSpot 488 was diluted to a 1:100 ratio with Dulbecco's Phosphate-Buffered Saline (DPBS).
Each dish was treated with 4 ml of this staining solution and incubated at 37°C for 30 minutes.
Post-incubation, cell imaging was performed using the EVOS fluorescent microscope to detect the GFP signal, as shown in Figure [@fig:sup:crispr:fig1].

**Fluorescence-Activated Cell Sorting (FACS)**

Cells were collected into 50 mL tubes and immediately cooled.
They were then centrifuged at 500 x g for 5 minutes at 4°C.
Following a wash with DPBS, the cell pellets were resuspended in FACS Sorting Buffer, which consists of 1x DPBS without Ca²⁺/Mg²⁺, 2.5 mM EDTA, 25 mM HEPES, and 1% BSA.
This solution was filter sterilized and maintained at 4°C.
For disaggregation into single cells, gentle pipetting was employed.

The cell suspension was subsequently passed through a cell strainer (Falcon, Cat.
352235) and kept on ice, shielded from light.
Sorting was performed using a FACSJazz sorter equipped with a 100 µm nozzle.
Approximately 20% of cells exhibiting either high or low GFP expression (Figure @fig:sup:crispr:fig2) were collected into 15 mL tubes.

Post-sorting, the cells were centrifuged immediately, and the resulting pellets were stored at -80°C for subsequent genomic DNA extraction.

**Genomic DNA Isolation and Verification**

Three types of genomic DNA (gDNA) samples—Un-Sorted Control, lentiV2 GFP-High, and lentiV2 GFP-Low—were isolated using the QIAamp DNA Blood Mini Kit (Qiagen, Cat.
No.
51104).
The quality and quantity of the extracted gDNA were assessed using UV spectroscopy with a Nanodrop device.
Each sample yielded between 80-160 µg of gDNA.
The presence of the sgRNA cassette and lentiviral-specific transgene within the isolated gDNA was confirmed via PCR analysis, as shown in Figure @fig:sup:crispr:fig3.

**Illumina Libraries Generation and Sequencing**

The sgRNA cassette fragment was amplified using P5 and P7 primers, following the protocol described in [@pmid:26780180], with primer sequences adapted from the Broad Institute protocol (see Figure @fig:sup:crispr:table1).
The P5 primer included a stagger sequence of 0-8 nucleotides, and the P7 primer contained an 8bp unique barcode.
Primers were synthesized by Integrated DNA Technologies (IDT) and were purified using polyacrylamide gel electrophoresis (PAGE).

For each experimental condition, 32 PCR reactions were prepared.
Each 100µL PCR reaction contained approximately 5µg of genomic DNA (gDNA), and 5µL of each 10µM primer (P5 and P7).
The reactions utilized ExTaq DNA Polymerase (TaKaRa, Cat.
RR001A) to amplify the target amplicon.
The PCR conditions were set as follows: initial denaturation at 95°C for 1 minute; followed by 24 cycles of denaturation at 94°C for 30 seconds, annealing at 52.5°C for 30 seconds, and extension at 72°C for 30 seconds; with a final elongation at 72°C for 10 minutes.
The expected size of the PCR products was between 285bp and 293bp (refer to Figure @fig:sup:crispr:fig4 A).

Following amplification, PCR products from the same condition were combined and purified using SPRIselect beads (Beckman Coulter, Cat.
B23318).
The concentration of the purified Illumina libraries was measured using a Qubit fluorometer, and the quality was assessed on a Bioanalyzer with a High Sensitivity DNA Chip.
A single peak around 285bp was anticipated (see Figure @fig:sup:crispr:fig4 B).

Finally, the prepared Illumina library samples were sequenced on a NovaSeq 6000 system.
Samples were pooled and loaded onto an SP flow cell, incorporating a 20% PhiX control v3 library spike-in to ensure sequencing accuracy.


## Data availability

All the main datasets generated in this study are available at [https://doi.org/10.5281/zenodo.8071382](https://doi.org/10.5281/zenodo.8071382) [@doi:10.5281/zenodo.8071382] and the GitHub repository [https://github.com/greenelab/phenoplier](https://github.com/greenelab/phenoplier).

The main input datasets used are TWAS from PhenomeXcan [@doi:10.1126/sciadv.aba2083] for 4,091 traits and from the Electronic Medical Records and Genomics (eMERGE) network phase III [@doi:10.1101/2021.10.21.21265225] for 309 traits; transcriptional responses to small molecule perturbations from LINCS L1000 [@doi:10.1016/j.cell.2017.10.049] that were further preprocessed and mapped to DrugBank IDs from [@doi:10.5281/zenodo.47223]; latent space/gene module models from MultiPLIER [@doi:10.1016/j.cels.2019.04.003].

The datasets from PhenomeXcan, LINCS L1000, and MultiPLIER are publicly accessible.
All significant findings from the phenome-wide transcriptome-wide association studies (TWAS) involving eMERGE and Penn Medicine BioBank (PMBB) are detailed in [@doi:10.1101/2021.10.21.21265225].
Due to institutional privacy policies, the individual-level raw data from PMBB cannot be made publicly available.
For access to these data, please contact the Penn Medicine Biobank at [https://pmbb.med.upenn.edu/pmbb/](https://pmbb.med.upenn.edu/pmbb/).
Additionally, data from phase III of the eMERGE network is available on dbGAP under the accession number phs001584.v2.p2.


## Code availability

The code necessary to reproduce all the analyses in this work is available at [https://doi.org/10.5281/zenodo.8071382](https://doi.org/10.5281/zenodo.8071382) [@doi:10.5281/zenodo.8071382] and the GitHub repository [https://github.com/greenelab/phenoplier](https://github.com/greenelab/phenoplier).

For the CRISPR screening analysis, we utilized FlowJo version 10.7 and FACS Jazz Software version 1.1.
The data analysis was conducted using Python 3.8 and R 3.6, supported by a suite of computational packages.
Specifically, the Python environment included Jupyter Lab (2.2), pandas (1.1), matplotlib (3.3), seaborn (0.11), numpy (1.19), scipy (1.5), scikit-learn (0.23), and umap-learn (0.4).
For R, we employed Bioconductor (3.10), clusterProfiler (3.14), clustree (0.4), and fgsea (1.17).

Additionally, we developed and published several scripts and notebooks under an open-source license to ensure reproducibility and transparency of our methodology.
Comprehensive documentation was prepared detailing every step required to replicate the analyses.
To facilitate the use of the same computational environment employed in our study, we provide a Docker image.
Moreover, we offer a demonstration version to enable rapid testing of the methods using actual data.
